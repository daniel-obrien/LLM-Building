{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install \"tensorflow-text==2.11.*\"\n",
        "%pip install tensorflow_datasets"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: tensorflow-text==2.11.* in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (2.11.0)\nRequirement already satisfied: tensorflow-hub>=0.8.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow-text==2.11.*) (0.16.1)\nRequirement already satisfied: tensorflow<2.12,>=2.11.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow-text==2.11.*) (2.11.1)\nRequirement already satisfied: absl-py>=1.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (1.6.3)\nRequirement already satisfied: flatbuffers>=2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (24.3.25)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (1.43.0)\nRequirement already satisfied: h5py>=2.9.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (3.11.0)\nRequirement already satisfied: keras<2.12,>=2.11.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (2.11.0)\nRequirement already satisfied: libclang>=13.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (18.1.1)\nRequirement already satisfied: numpy>=1.20 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (1.25.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (3.3.0)\nRequirement already satisfied: packaging in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (23.0)\nCollecting protobuf<3.20,>=3.9.2 (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*)\n  Using cached protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\nRequirement already satisfied: setuptools in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (67.8.0)\nRequirement already satisfied: six>=1.12.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (1.16.0)\nRequirement already satisfied: tensorboard<2.12,>=2.11 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (2.11.2)\nRequirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (2.11.0)\nRequirement already satisfied: termcolor>=1.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (4.11.0)\nRequirement already satisfied: wrapt>=1.11.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (1.16.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (0.36.0)\nRequirement already satisfied: tf-keras>=2.14.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow-hub>=0.8.0->tensorflow-text==2.11.*) (2.15.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (0.38.4)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (2.20.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (0.4.6)\nRequirement already satisfied: markdown>=2.6.8 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (3.4.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (0.6.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (1.8.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (2.3.6)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (5.3.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (4.9)\nRequirement already satisfied: urllib3<2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (1.26.16)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (2023.5.7)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (0.5.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text==2.11.*) (3.2.2)\nInstalling collected packages: protobuf\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-datasets 4.9.4 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed protobuf-3.19.6\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: tensorflow_datasets in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (4.9.4)\nRequirement already satisfied: absl-py in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow_datasets) (1.4.0)\nRequirement already satisfied: click in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow_datasets) (8.0.4)\nRequirement already satisfied: dm-tree in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow_datasets) (0.1.8)\nRequirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow_datasets) (1.7.0)\nRequirement already satisfied: numpy in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow_datasets) (1.25.0)\nRequirement already satisfied: promise in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow_datasets) (2.3)\nCollecting protobuf>=3.20 (from tensorflow_datasets)\n  Using cached protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\nRequirement already satisfied: psutil in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow_datasets) (5.9.0)\nRequirement already satisfied: requests>=2.19.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow_datasets) (2.31.0)\nRequirement already satisfied: tensorflow-metadata in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow_datasets) (1.14.0)\nRequirement already satisfied: termcolor in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow_datasets) (2.4.0)\nRequirement already satisfied: toml in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow_datasets) (0.10.2)\nRequirement already satisfied: tqdm in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow_datasets) (4.65.0)\nRequirement already satisfied: wrapt in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow_datasets) (1.16.0)\nRequirement already satisfied: array-record>=0.5.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow_datasets) (0.5.1)\nRequirement already satisfied: fsspec in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (2023.6.0)\nRequirement already satisfied: importlib_resources in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (6.4.0)\nRequirement already satisfied: typing_extensions in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (4.11.0)\nRequirement already satisfied: zipp in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (3.15.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow_datasets) (2023.5.7)\nRequirement already satisfied: six in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from promise->tensorflow_datasets) (1.16.0)\nRequirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from tensorflow-metadata->tensorflow_datasets) (1.59.1)\n  Using cached protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\nInstalling collected packages: protobuf\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.19.6\n    Uninstalling protobuf-3.19.6:\n      Successfully uninstalled protobuf-3.19.6\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.11.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed protobuf-3.20.3\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1712757926442
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n",
        "%pip uninstall -y -q tensorflow keras tensorflow-estimator tensorflow-text\n",
        "%pip install protobuf~=3.20.3"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "UsageError: Line magic function `%apt` not found.\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_text\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n2024-04-10 16:22:37.874924: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2024-04-10 16:22:40.408696: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2024-04-10 16:22:40.408748: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2024-04-10 16:22:45.222311: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2024-04-10 16:22:45.222447: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2024-04-10 16:22:45.222460: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712766172533
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en',\n",
        "                               with_info=True,\n",
        "                               as_supervised=True)\n",
        "\n",
        "train_examples, val_examples = examples['train'], examples['validation']"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2024-04-10 16:23:02.762374: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n2024-04-10 16:23:02.762431: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (judes-testing): /proc/driver/nvidia/version does not exist\n2024-04-10 16:23:02.774146: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712766184216
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for pt_examples, en_examples in train_examples.batch(3).take(1):\n",
        "  print('> Examples in Portuguese:')\n",
        "  for pt in pt_examples.numpy():\n",
        "    print(pt.decode('utf-8'))\n",
        "  print()\n",
        "\n",
        "  print('> Examples in English:')\n",
        "  for en in en_examples.numpy():\n",
        "    print(en.decode('utf-8'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "> Examples in Portuguese:\ne quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .\nmas e se estes fatores fossem ativos ?\nmas eles não tinham a curiosidade de me testar .\n\n> Examples in English:\nand when you improve searchability , you actually take away the one advantage of print , which is serendipity .\nbut what if it were active ?\nbut they did n't test for curiosity .\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2024-04-10 16:23:10.216446: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712766191488
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'ted_hrlr_translate_pt_en_converter'\n",
        "tf.keras.utils.get_file(\n",
        "    f'{model_name}.zip',\n",
        "    f'https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip',\n",
        "    cache_dir='.', cache_subdir='', extract=True\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Downloading data from https://storage.googleapis.com/download.tensorflow.org/models/ted_hrlr_translate_pt_en_converter.zip\n\r  8192/184801 [>.............................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 49152/184801 [======>.......................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 81920/184801 [============>.................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r147456/184801 [======================>.......] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r184801/184801 [==============================] - 0s 1us/step\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "'./ted_hrlr_translate_pt_en_converter.zip'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758951006
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizers = tf.saved_model.load(model_name)"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758951872
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[item for item in dir(tokenizers.en) if not item.startswith('_')]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "['detokenize',\n 'get_reserved_tokens',\n 'get_vocab_path',\n 'get_vocab_size',\n 'lookup',\n 'tokenize',\n 'tokenizer',\n 'vocab']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758952454
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('> This is a batch of strings:')\n",
        "for en in en_examples.numpy():\n",
        "  print(en.decode('utf-8'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "> This is a batch of strings:\nand when you improve searchability , you actually take away the one advantage of print , which is serendipity .\nbut what if it were active ?\nbut they did n't test for curiosity .\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758952803
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = tokenizers.en.tokenize(en_examples)\n",
        "\n",
        "print('> This is a padded-batch of token IDs:')\n",
        "for row in encoded.to_list():\n",
        "  print(row)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "> This is a padded-batch of token IDs:\n[2, 72, 117, 79, 1259, 1491, 2362, 13, 79, 150, 184, 311, 71, 103, 2308, 74, 2679, 13, 148, 80, 55, 4840, 1434, 2423, 540, 15, 3]\n[2, 87, 90, 107, 76, 129, 1852, 30, 3]\n[2, 87, 83, 149, 50, 9, 56, 664, 85, 2512, 15, 3]\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758953066
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "round_trip = tokenizers.en.detokenize(encoded)\n",
        "\n",
        "print('> This is human-readable text:')\n",
        "for line in round_trip.numpy():\n",
        "  print(line.decode('utf-8'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "> This is human-readable text:\nand when you improve searchability , you actually take away the one advantage of print , which is serendipity .\nbut what if it were active ?\nbut they did n ' t test for curiosity .\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758953324
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('> This is the text split into tokens:')\n",
        "tokens = tokenizers.en.lookup(encoded)\n",
        "tokens"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "> This is the text split into tokens:\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "<tf.RaggedTensor [[b'[START]', b'and', b'when', b'you', b'improve', b'search', b'##ability',\n  b',', b'you', b'actually', b'take', b'away', b'the', b'one', b'advantage',\n  b'of', b'print', b',', b'which', b'is', b's', b'##ere', b'##nd', b'##ip',\n  b'##ity', b'.', b'[END]']                                                 ,\n [b'[START]', b'but', b'what', b'if', b'it', b'were', b'active', b'?',\n  b'[END]']                                                           ,\n [b'[START]', b'but', b'they', b'did', b'n', b\"'\", b't', b'test', b'for',\n  b'curiosity', b'.', b'[END]']                                          ]>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758953655
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = []\n",
        "\n",
        "for pt_examples, en_examples in train_examples.batch(1024):\n",
        "  pt_tokens = tokenizers.pt.tokenize(pt_examples)\n",
        "  lengths.append(pt_tokens.row_lengths())\n",
        "\n",
        "  en_tokens = tokenizers.en.tokenize(en_examples)\n",
        "  lengths.append(en_tokens.row_lengths())\n",
        "  print('.', end='', flush=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "..................................................."
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758958099
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_lengths = np.concatenate(lengths)\n",
        "\n",
        "plt.hist(all_lengths, np.linspace(0, 500, 101))\n",
        "plt.ylim(plt.ylim())\n",
        "max_length = max(all_lengths)\n",
        "plt.plot([max_length, max_length], plt.ylim())\n",
        "plt.title(f'Maximum tokens per example: {max_length}');"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758958871
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TOKENS=128\n",
        "def prepare_batch(pt, en):\n",
        "    pt = tokenizers.pt.tokenize(pt)      # Output is ragged.\n",
        "    pt = pt[:, :MAX_TOKENS]    # Trim to MAX_TOKENS.\n",
        "    pt = pt.to_tensor()  # Convert to 0-padded dense Tensor\n",
        "\n",
        "    en = tokenizers.en.tokenize(en)\n",
        "    en = en[:, :(MAX_TOKENS+1)]\n",
        "    en_inputs = en[:, :-1].to_tensor()  # Drop the [END] tokens\n",
        "    en_labels = en[:, 1:].to_tensor()   # Drop the [START] tokens\n",
        "\n",
        "    return (pt, en_inputs), en_labels"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758959166
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758959612
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_batches(ds):\n",
        "  return (\n",
        "      ds\n",
        "      .shuffle(BUFFER_SIZE)\n",
        "      .batch(BATCH_SIZE)\n",
        "      .map(prepare_batch, tf.data.AUTOTUNE)\n",
        "      .prefetch(buffer_size=tf.data.AUTOTUNE))"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758959868
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and validation set batches.\n",
        "train_batches = make_batches(train_examples)\n",
        "val_batches = make_batches(val_examples)"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758960129
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for (pt, en), en_labels in train_batches.take(1):\n",
        "  break\n",
        "\n",
        "print(pt.shape)\n",
        "print(en.shape)\n",
        "print(en_labels.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(64, 49)\n(64, 48)\n(64, 48)\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758960391
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(en[0][:10])\n",
        "print(en_labels[0][:10])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "tf.Tensor([  2  72  82  78 834  37 123 205 389  74], shape=(10,), dtype=int64)\ntf.Tensor([ 72  82  78 834  37 123 205 389  74 218], shape=(10,), dtype=int64)\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758960612
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(length, depth):\n",
        "  depth = depth/2\n",
        "\n",
        "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
        "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
        "\n",
        "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
        "  angle_rads = positions * angle_rates      # (pos, depth)\n",
        "\n",
        "  pos_encoding = np.concatenate(\n",
        "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "      axis=-1) \n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758960830
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "  def __init__(self, vocab_size, d_model):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True) \n",
        "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
        "\n",
        "  def compute_mask(self, *args, **kwargs):\n",
        "    return self.embedding.compute_mask(*args, **kwargs)\n",
        "\n",
        "  def call(self, x):\n",
        "    length = tf.shape(x)[1]\n",
        "    x = self.embedding(x)\n",
        "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "    return x"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758961054
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_pt = PositionalEmbedding(vocab_size=tokenizers.pt.get_vocab_size(), d_model=512)\n",
        "embed_en = PositionalEmbedding(vocab_size=tokenizers.en.get_vocab_size(), d_model=512)\n",
        "\n",
        "pt_emb = embed_pt(pt)\n",
        "en_emb = embed_en(en)"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758961311
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "en_emb._keras_mask"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "<tf.Tensor: shape=(64, 48), dtype=bool, numpy=\narray([[ True,  True,  True, ..., False, False, False],\n       [ True,  True,  True, ..., False, False, False],\n       [ True,  True,  True, ..., False, False, False],\n       ...,\n       [ True,  True,  True, ..., False, False, False],\n       [ True,  True,  True, ..., False, False, False],\n       [ True,  True,  True, ..., False, False, False]])>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758961572
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758961812
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = {'color': 'blue', 'age': 22, 'type': 'pickup'}\n",
        "result = d['color']"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758962033
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttention(BaseAttention):\n",
        "  def call(self, x, context):\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query=x,\n",
        "        key=context,\n",
        "        value=context,\n",
        "        return_attention_scores=True)\n",
        "\n",
        "    # Cache the attention scores for plotting later.\n",
        "    self.last_attn_scores = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758962247
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_ca = CrossAttention(num_heads=2, key_dim=512)\n",
        "\n",
        "print(pt_emb.shape)\n",
        "print(en_emb.shape)\n",
        "print(sample_ca(en_emb, pt_emb).shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(64, 49, 512)\n(64, 48, 512)\n(64, 48, 512)\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758962535
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GlobalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758962797
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_gsa = GlobalSelfAttention(num_heads=2, key_dim=512)\n",
        "\n",
        "print(pt_emb.shape)\n",
        "print(sample_gsa(pt_emb).shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(64, 49, 512)\n(64, 49, 512)\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758963088
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x,\n",
        "        use_causal_mask = True)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758963327
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_csa = CausalSelfAttention(num_heads=2, key_dim=512)\n",
        "\n",
        "print(en_emb.shape)\n",
        "print(sample_csa(en_emb).shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(64, 48, 512)\n(64, 48, 512)\n"
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758963594
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out1 = sample_csa(embed_en(en[:, :3])) \n",
        "out2 = sample_csa(embed_en(en))[:, :3]\n",
        "\n",
        "tf.reduce_max(abs(out1 - out2)).numpy()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 32,
          "data": {
            "text/plain": "4.7683716e-07"
          },
          "metadata": {}
        }
      ],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758963892
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.seq = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),\n",
        "      tf.keras.layers.Dense(d_model),\n",
        "      tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "    self.add = tf.keras.layers.Add()\n",
        "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.add([x, self.seq(x)])\n",
        "    x = self.layer_norm(x) \n",
        "    return x"
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758964160
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_ffn = FeedForward(512, 2048)\n",
        "\n",
        "print(en_emb.shape)\n",
        "print(sample_ffn(en_emb).shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(64, 48, 512)\n(64, 48, 512)\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758964450
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.self_attention = GlobalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.self_attention(x)\n",
        "    x = self.ffn(x)\n",
        "    return x"
      ],
      "outputs": [],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758964758
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_encoder_layer = EncoderLayer(d_model=512, num_heads=8, dff=2048)\n",
        "\n",
        "print(pt_emb.shape)\n",
        "print(sample_encoder_layer(pt_emb).shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(64, 49, 512)\n(64, 49, 512)\n"
        }
      ],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758965070
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads,\n",
        "               dff, vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(\n",
        "        vocab_size=vocab_size, d_model=d_model)\n",
        "\n",
        "    self.enc_layers = [\n",
        "        EncoderLayer(d_model=d_model,\n",
        "                     num_heads=num_heads,\n",
        "                     dff=dff,\n",
        "                     dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x):\n",
        "    # `x` is token-IDs shape: (batch, seq_len)\n",
        "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "\n",
        "    # Add dropout.\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x)\n",
        "\n",
        "    return x  # Shape `(batch_size, seq_len, d_model)`."
      ],
      "outputs": [],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758965353
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the encoder.\n",
        "sample_encoder = Encoder(num_layers=4,\n",
        "                         d_model=512,\n",
        "                         num_heads=8,\n",
        "                         dff=2048,\n",
        "                         vocab_size=8500)\n",
        "\n",
        "sample_encoder_output = sample_encoder(pt, training=False)\n",
        "\n",
        "# Print the shape.\n",
        "print(pt.shape)\n",
        "print(sample_encoder_output.shape)  # Shape `(batch_size, input_seq_len, d_model)`."
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(64, 49)\n(64, 49, 512)\n"
        }
      ],
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758967882
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,\n",
        "               *,\n",
        "               d_model,\n",
        "               num_heads,\n",
        "               dff,\n",
        "               dropout_rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.causal_self_attention = CausalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.cross_attention = CrossAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x, context):\n",
        "    x = self.causal_self_attention(x=x)\n",
        "    x = self.cross_attention(x=x, context=context)\n",
        "\n",
        "    # Cache the last attention scores for plotting later\n",
        "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
        "\n",
        "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "    return x"
      ],
      "outputs": [],
      "execution_count": 39,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758968100
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_decoder_layer = DecoderLayer(d_model=512, num_heads=8, dff=2048)\n",
        "\n",
        "sample_decoder_layer_output = sample_decoder_layer(\n",
        "    x=en_emb, context=pt_emb)\n",
        "\n",
        "print(en_emb.shape)\n",
        "print(pt_emb.shape)\n",
        "print(sample_decoder_layer_output.shape)  # `(batch_size, seq_len, d_model)`"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(64, 48, 512)\n(64, 49, 512)\n(64, 48, 512)\n"
        }
      ],
      "execution_count": 40,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758970821
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
        "               dropout_rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
        "                                             d_model=d_model)\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "    self.dec_layers = [\n",
        "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
        "                     dff=dff, dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "\n",
        "    self.last_attn_scores = None\n",
        "\n",
        "  def call(self, x, context):\n",
        "    # `x` is token-IDs shape (batch, target_seq_len)\n",
        "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x  = self.dec_layers[i](x, context)\n",
        "\n",
        "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
        "\n",
        "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
        "    return x"
      ],
      "outputs": [],
      "execution_count": 41,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758971078
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the decoder.\n",
        "sample_decoder = Decoder(num_layers=4,\n",
        "                         d_model=512,\n",
        "                         num_heads=8,\n",
        "                         dff=2048,\n",
        "                         vocab_size=8000)\n",
        "\n",
        "output = sample_decoder(\n",
        "    x=en,\n",
        "    context=pt_emb)\n",
        "\n",
        "# Print the shapes.\n",
        "print(en.shape)\n",
        "print(pt_emb.shape)\n",
        "print(output.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(64, 48)\n(64, 49, 512)\n(64, 48, 512)\n"
        }
      ],
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758979070
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_decoder.last_attn_scores.shape  # (batch, heads, target_seq, input_seq)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 43,
          "data": {
            "text/plain": "TensorShape([64, 8, 48, 49])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 43,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758979417
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
        "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=input_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=target_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
        "    # first argument.\n",
        "    context, x  = inputs\n",
        "\n",
        "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
        "\n",
        "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
        "\n",
        "    # Final linear layer output.\n",
        "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
        "\n",
        "    try:\n",
        "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
        "      # b/250038731\n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    # Return the final output and the attention weights.\n",
        "    return logits"
      ],
      "outputs": [],
      "execution_count": 44,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758979710
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1"
      ],
      "outputs": [],
      "execution_count": 45,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758979950
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=tokenizers.pt.get_vocab_size().numpy(),\n",
        "    target_vocab_size=tokenizers.en.get_vocab_size().numpy(),\n",
        "    dropout_rate=dropout_rate)"
      ],
      "outputs": [],
      "execution_count": 46,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758980176
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = transformer((pt, en))\n",
        "\n",
        "print(en.shape)\n",
        "print(pt.shape)\n",
        "print(output.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(64, 48)\n(64, 49)\n(64, 48, 7010)\n"
        }
      ],
      "execution_count": 47,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758981364
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = transformer.decoder.dec_layers[-1].last_attn_scores\n",
        "print(attn_scores.shape)  # (batch, heads, target_seq, input_seq)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(64, 8, 48, 49)\n"
        }
      ],
      "execution_count": 48,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758981578
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model: \"transformer\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n encoder_1 (Encoder)         multiple                  3632768   \n                                                                 \n decoder_1 (Decoder)         multiple                  5647104   \n                                                                 \n dense_38 (Dense)            multiple                  904290    \n                                                                 \n=================================================================\nTotal params: 10,184,162\nTrainable params: 10,184,162\nNon-trainable params: 0\n_________________________________________________________________\n"
        }
      ],
      "execution_count": 49,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758981834
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, dtype=tf.float32)\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "outputs": [],
      "execution_count": 50,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758982073
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ],
      "outputs": [],
      "execution_count": 51,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758982340
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(learning_rate(tf.range(40000, dtype=tf.float32)))\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.xlabel('Train Step')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 52,
          "data": {
            "text/plain": "Text(0.5, 0, 'Train Step')"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ],
      "execution_count": 52,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758982697
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_loss(label, pred):\n",
        "  mask = label != 0\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "  loss = loss_object(label, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "  return loss\n",
        "\n",
        "\n",
        "def masked_accuracy(label, pred):\n",
        "  pred = tf.argmax(pred, axis=2)\n",
        "  label = tf.cast(label, pred.dtype)\n",
        "  match = label == pred\n",
        "\n",
        "  mask = label != 0\n",
        "\n",
        "  match = match & mask\n",
        "\n",
        "  match = tf.cast(match, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ],
      "outputs": [],
      "execution_count": 53,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758983000
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.compile(\n",
        "    loss=masked_loss,\n",
        "    optimizer=optimizer,\n",
        "    metrics=[masked_accuracy])"
      ],
      "outputs": [],
      "execution_count": 54,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712758983303
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.fit(train_batches,\n",
        "                epochs=20,\n",
        "                validation_data=val_batches)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/20\n 29/810 [>.............................] - ETA: 1:51:43 - loss: 8.8489 - masked_accuracy: 8.7083e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 30/810 [>.............................] - ETA: 1:54:34 - loss: 8.8471 - masked_accuracy: 0.0011    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r237/810 [=======>......................] - ETA: 1:23:18 - loss: 8.2871 - masked_accuracy: 0.0563\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r238/810 [=======>......................] - ETA: 1:23:03 - loss: 8.2835 - masked_accuracy: 0.0566"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_batches\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 55,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712761094886
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Translator(tf.Module):\n",
        "  def __init__(self, tokenizers, transformer):\n",
        "    self.tokenizers = tokenizers\n",
        "    self.transformer = transformer\n",
        "\n",
        "  def __call__(self, sentence, max_length=MAX_TOKENS):\n",
        "    # The input sentence is Portuguese, hence adding the `[START]` and `[END]` tokens.\n",
        "    assert isinstance(sentence, tf.Tensor)\n",
        "    if len(sentence.shape) == 0:\n",
        "      sentence = sentence[tf.newaxis]\n",
        "\n",
        "    sentence = self.tokenizers.pt.tokenize(sentence).to_tensor()\n",
        "\n",
        "    encoder_input = sentence\n",
        "\n",
        "    # As the output language is English, initialize the output with the\n",
        "    # English `[START]` token.\n",
        "    start_end = self.tokenizers.en.tokenize([''])[0]\n",
        "    start = start_end[0][tf.newaxis]\n",
        "    end = start_end[1][tf.newaxis]\n",
        "\n",
        "    # `tf.TensorArray` is required here (instead of a Python list), so that the\n",
        "    # dynamic-loop can be traced by `tf.function`.\n",
        "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
        "    output_array = output_array.write(0, start)\n",
        "\n",
        "    for i in tf.range(max_length):\n",
        "      output = tf.transpose(output_array.stack())\n",
        "      predictions = self.transformer([encoder_input, output], training=False)\n",
        "\n",
        "      # Select the last token from the `seq_len` dimension.\n",
        "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
        "\n",
        "      predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "      # Concatenate the `predicted_id` to the output which is given to the\n",
        "      # decoder as its input.\n",
        "      output_array = output_array.write(i+1, predicted_id[0])\n",
        "\n",
        "      if predicted_id == end:\n",
        "        break\n",
        "\n",
        "    output = tf.transpose(output_array.stack())\n",
        "    # The output shape is `(1, tokens)`.\n",
        "    text = tokenizers.en.detokenize(output)[0]  # Shape: `()`.\n",
        "\n",
        "    tokens = tokenizers.en.lookup(output)[0]\n",
        "\n",
        "    # `tf.function` prevents us from using the attention_weights that were\n",
        "    # calculated on the last iteration of the loop.\n",
        "    # So, recalculate them outside the loop.\n",
        "    self.transformer([encoder_input, output[:,:-1]], training=False)\n",
        "    attention_weights = self.transformer.decoder.last_attn_scores\n",
        "\n",
        "    return text, tokens, attention_weights"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712761095342
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator(tokenizers, transformer)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712761095378
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_translation(sentence, tokens, ground_truth):\n",
        "  print(f'{\"Input:\":15s}: {sentence}')\n",
        "  print(f'{\"Prediction\":15s}: {tokens.numpy().decode(\"utf-8\")}')\n",
        "  print(f'{\"Ground truth\":15s}: {ground_truth}')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712761095402
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'este é um problema que temos que resolver.'\n",
        "ground_truth = 'this is a problem we have to solve .'\n",
        "\n",
        "translated_text, translated_tokens, attention_weights = translator(\n",
        "    tf.constant(sentence))\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712761095428
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'os meus vizinhos ouviram sobre esta ideia.'\n",
        "ground_truth = 'and my neighboring homes heard about this idea .'\n",
        "\n",
        "translated_text, translated_tokens, attention_weights = translator(\n",
        "    tf.constant(sentence))\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712761095454
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.'\n",
        "ground_truth = \"so i'll just share with you some stories very quickly of some magical things that have happened.\"\n",
        "\n",
        "translated_text, translated_tokens, attention_weights = translator(\n",
        "    tf.constant(sentence))\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712761095479
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'este é o primeiro livro que eu fiz.'\n",
        "ground_truth = \"this is the first book i've ever done.\"\n",
        "\n",
        "translated_text, translated_tokens, attention_weights = translator(\n",
        "    tf.constant(sentence))\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712761095504
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_attention_head(in_tokens, translated_tokens, attention):\n",
        "  # The model didn't generate `<START>` in the output. Skip it.\n",
        "  translated_tokens = translated_tokens[1:]\n",
        "\n",
        "  ax = plt.gca()\n",
        "  ax.matshow(attention)\n",
        "  ax.set_xticks(range(len(in_tokens)))\n",
        "  ax.set_yticks(range(len(translated_tokens)))\n",
        "\n",
        "  labels = [label.decode('utf-8') for label in in_tokens.numpy()]\n",
        "  ax.set_xticklabels(\n",
        "      labels, rotation=90)\n",
        "\n",
        "  labels = [label.decode('utf-8') for label in translated_tokens.numpy()]\n",
        "  ax.set_yticklabels(labels)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712761095528
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "head = 0\n",
        "# Shape: `(batch=1, num_heads, seq_len_q, seq_len_k)`.\n",
        "attention_heads = tf.squeeze(attention_weights, 0)\n",
        "attention = attention_heads[head]\n",
        "attention.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712761095555
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_tokens = tf.convert_to_tensor([sentence])\n",
        "in_tokens = tokenizers.pt.tokenize(in_tokens).to_tensor()\n",
        "in_tokens = tokenizers.pt.lookup(in_tokens)[0]\n",
        "in_tokens"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712761095578
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translated_tokens"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712761095600
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_attention_head(in_tokens, translated_tokens, attention)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712761095624
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_attention_weights(sentence, translated_tokens, attention_heads):\n",
        "  in_tokens = tf.convert_to_tensor([sentence])\n",
        "  in_tokens = tokenizers.pt.tokenize(in_tokens).to_tensor()\n",
        "  in_tokens = tokenizers.pt.lookup(in_tokens)[0]\n",
        "\n",
        "  fig = plt.figure(figsize=(16, 8))\n",
        "\n",
        "  for h, head in enumerate(attention_heads):\n",
        "    ax = fig.add_subplot(2, 4, h+1)\n",
        "\n",
        "    plot_attention_head(in_tokens, translated_tokens, head)\n",
        "\n",
        "    ax.set_xlabel(f'Head {h+1}')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712761095648
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_attention_weights(sentence,\n",
        "                       translated_tokens,\n",
        "                       attention_weights[0])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712761095679
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'Eu li sobre triceratops na enciclopédia.'\n",
        "ground_truth = 'I read about triceratops in the encyclopedia.'\n",
        "\n",
        "translated_text, translated_tokens, attention_weights = translator(\n",
        "    tf.constant(sentence))\n",
        "print_translation(sentence, translated_text, ground_truth)\n",
        "\n",
        "plot_attention_weights(sentence, translated_tokens, attention_weights[0])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712761095763
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ExportTranslator(tf.Module):\n",
        "  def __init__(self, translator):\n",
        "    self.translator = translator\n",
        "\n",
        "  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
        "  def __call__(self, sentence):\n",
        "    (result,\n",
        "     tokens,\n",
        "     attention_weights) = self.translator(sentence, max_length=MAX_TOKENS)\n",
        "\n",
        "    return result"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712761095913
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translator = ExportTranslator(translator)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712761096074
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translator('este é o primeiro livro que eu fiz.').numpy()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712761096154
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(translator, export_dir='translator')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712761096193
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reloaded = tf.saved_model.load('translator')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712761096224
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reloaded('este é o primeiro livro que eu fiz.').numpy()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1712761096248
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}